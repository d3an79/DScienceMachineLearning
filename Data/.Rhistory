summary(lm(mpg ~ factor(am) + ., mtcars))
summary(lm(mpg ~ factor(am) + disp + hp + drat + wt +
qsec + vs + gear + carb, mtcars))
summary(lm(mpg ~ factor(am) + disp + hp + drat + wt +
qsec + gear + carb, mtcars))
summary(lm(mpg ~ factor(am) + disp + hp + drat + wt +
qsec + gear, mtcars))
summary(lm(mpg ~ factor(am) + disp + hp + drat + wt +
qsec, mtcars))
summary(lm(mpg ~ factor(am) + disp + hp + wt +
qsec, mtcars))
summary(lm(mpg ~ factor(am) + hp + wt + qsec, mtcars))
summary(lm(mpg ~ factor(am) + wt + qsec, mtcars))
summary(lm(mpg ~ factor(am) + hp + wt + qsec, mtcars))
summary(lm(mpg ~ factor(am) + wt + qsec, mtcars))
fit8 <- lm(mpg ~ factor(am) + wt + qsec, mtcars)
fit8
summary(fit8)
as.numeric(coef(fit8)[2])
fit8 <- lm(mpg ~ factor(am) + wt, mtcars)
fit8 <- lm(mpg ~ factor(am) + wt + qsec, mtcars)
summary(fit8 <- lm(mpg ~ factor(am) + wt, mtcars))
fit8 <- lm(mpg ~ factor(am) + wt + qsec, mtcars)
plot(predict(fit8), resid(fit8))
head(sort(round(hatvalues(fit8),3), decreasing=T), 5)
head(sort(round(dfbeta(fit5),3)[,1], decreasing=T), 5)
head(sort(round(dfbeta(fit8),3)[,1], decreasing=T), 5)
plot(round(dfbeta(fit8),3)[,1])
coef(fit8)
data(mtcars)
sapply(mtcars$am, mean)
sapply(mtcars$mpg, mean)
aggregate(mpg~am, mtcars, mean)
?mtcars
fit <- lm(mpg ~ factor(am) + wt + qsec, mtcars)
plot(predict(fit8), resid(fit8), title="")
plot(predict(fit), resid(fit8), title="")
plot(predict(fit), resid(fit), title="")
plot(predict(fit), resid(fit))
plot(predict(fit), resid(fit))
plot(predict(fit), resid(fit))
?plot
require(ggplot2)
ggplot(predict(fit, resid(fit)))
ggplot(aes(x=predict(fit, y=resid(fit))))
plot(predict(fit), resid(fit), main="residual values against predicted values", xlab="Predicted values", ylab="Residual values")
abline(h=0)
cor(resid(fit))
resid(fit)
plot(fit)
plot(fit)
plot(fit)[1]
plot(fit, which=1)
plot(fit, which=2)
plot(fit, which=3)
plot(fit, which=4)
plot(fit, which=5)
plot(fit, which=6)
head(sort(round(dffits(fit),3), decreasing=T), 5)
fit
summary(fit)
summary(fit)$r
summary(fit)$R
summary(fit)$residual
summary(fit)$residualstandard error
summary(fit)$multiple
?summary()
?summary()r.squared
r.squared(fit)
summary(lm.fit)
summary(lm.)
coef(fit)
r(fit)
adj.r.squared(fit)
adjusted(fit)
summary(fit)$adjusted
?mtcars
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, mtcars)
fit2 <- lm(mpg ~ factor(cyl) * wt, mtcars)
fit1
fit2
summary(fit1)
summary(fit2)
anova(fit1, fit2)
anova(fit2, fit1)
swirl()
library(swirl)
swirl()
fit <- lm(child ~ parent, galton)
sqrt(sum(fit$residuals^2/n-2))
sqrt(sum(fit$residuals^2)/n-2))
sqrt(sum(fit$residuals^2)/n-2)
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit)
1- sRes/sTot
summary(fit)$r
summary(fit)$r.squared
cor(galton$parent, galton$child)^2
library(swirl)
swirl()
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl2 <- (Fertility ~ Agriculture+Education+Catholic+Infant.Mortality, swiss)
mdl2 <- lm(Fertility ~ Agriculture+Education+Catholic+Infant.Mortality, swiss)
vif(mdl2)
rm(list=ls())
swirl()
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture+Examination+Education, swiss)
anova(fit1,fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1)-deviance(fit3))/3
n <- (deviance(fit1)-deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=F)
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1,fit3,fit5,fit6)
library(swirl)
swirl()
View(ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
predict(mdl, data.frame(ravenscore=c(0,3,6)))
predict(mdl, data.frame(ravenScore=c(0,3,6)))
predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95,1)
bye()
library(swirl())
swirl()
bye()
swirl()
var(rpois(1000,50))
nxt()
head(hits)
class(hits$date)
as.integer(head(hits$date))
mdl <- glm(visits ~ date, poisson,hits)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits$visits)
hits[704,]
lamda <- mdl$fitted.values[704]
lambda <- mdl$fitted.values[704]
qpois(.p6, lambda)
qpois(.96, lambda)
qpois(.95, lambda)
mdl2 <- gml(visits ~ date, poisson, hits, offset=log(visits+1))
mdl2 <- glm(visits ~ date, poisson, hits, offset=log(visits+1))
mdl2 <- glm(simplystats ~ date, poisson, hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.valus[704])
qpois(.95, mdl2$fitted.values[704])
library(MASS)
?shuttle
head(shuttle)
data(shuttle)
tail(shuttle)
str(shuttle)
fit1 <- glm(use ~ wind, binomial, shuttle)
summary(fit1)
exp(-0.03181)
exp(-0.25131)
exp(-0.25131)/1-exp(-0.03181)
fit2 <- glm(use ~ wind, binomial+magn, shuttle)
fit2 <- glm(use ~ wind+magn, binomial, shuttle)
summary(fit2)
data(InsectSprays)
str(InsectSprays)
fit4 <- glm(count ~ factor(spray), poisson, InsectSpray)
fit4 <- glm(count ~ factor(spray), poisson, InsectSprays)
summary(fit4)
exp(0.05588)
install.packages("caret")
install.packages("kernlab")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
rm(list=ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(concrete$CompressiveStrength ,pch=19)
qplot(concrete$CompressiveStrength ,pch=19)
plot(concrete$CompressiveStrength ,pch=19)
install.packages(Hmisc)
install.packages("Hmisc")
library(Hmisc)
?cut2
qplot(CompressiveStrength, data=concrete)
qplot(CompressiveStrength, colour=FlyAsh, data=concrete)
qplot(CompressiveStrength, colour=cement, data=concrete)
qplot(CompressiveStrength, colour=Cement, data=concrete)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$Cement)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$BlastFurnaceSlag)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$FlyAsh)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$Water)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$Superplasticizer)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$CoarseAggregate)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$FineAggregate)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$Age)
plot(concrete$CompressiveStrength ,pch=19, col=concrete$FlyAsh)
plot(training$CompressiveStrength ,pch=19)
plot(training$CompressiveStrength ,pch=19, col=concrete$Cement)
plot(training$CompressiveStrength ,pch=19, col=concrete$BlastFurnaceSlag)
plot(training$CompressiveStrength ,pch=19, col=concrete$FlyAsh)
plot(training$CompressiveStrength ,pch=19, col=concrete$Water)
plot(training$CompressiveStrength ,pch=19, col=concrete$Superplasticizer)
plot(training$CompressiveStrength ,pch=19, col=concrete$CoarseAggregate)
plot(training$CompressiveStrength ,pch=19, col=concrete$FineAggregate)
plot(training$CompressiveStrength ,pch=19, col=concrete$Age)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$)library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(concrete$CompressiveStrength ,pch=19, col=training$FlyAsh)
plot(training$CompressiveStrength ,pch=19, col=training$FlyAsh)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(training$CompressiveStrength, pch=19)
plot(training$CompressiveStrength, pch=19, col=training$Cement)
plot(training$CompressiveStrength, pch=19, col=training$Age)
plot(training$CompressiveStrength, pch=19, col=training$FineAggregate)
plot(training$CompressiveStrength, pch=19, col=training$CourseAggregate)
plot(training$CompressiveStrength, pch=19, col=training$Superplasticizer)
summary(training)
ead(training)
head(training)
plot(training$CompressiveStrength, pch=19, col=training$BlastFurnaceSlag)
plot(training$CompressiveStrength, pch=19, col=training$BlastFurnaceSl)
plot(training$CompressiveStrength, pch=19, col=training$BlastFurnaceSlag)
plot(training$CompressiveStrength, pch=19, col=training$Cement)
plot(training$CompressiveStrength, pch=19, col=training$Age)
plot(training$CompressiveStrength, pch=19, col=training$Cement)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
with(training, hist(SuperPlasticizer ))
with(training, hist(Superplasticizer ))
summary(training)
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
colnames(predictors)
predictors[= "IL%"]
predictors[predictors= "IL%"]
?with
with(predictors, predictors = "ICAM_1")
?grep
grep("ICAM_1", predictors)
grep("ICAM_1", predictors)
grep("IC", predictors)
View(predictors)
View(predictors)
View(predictors)
grep("ICAM_1", predictors)
grepl("ICAM_1", predictors)
grepl("IL", predictors)
grepl("IL%", predictors)
grepl("IL$", predictors)
dd <- "abcdefg"
grep("a", dd)
grep("ac", dd)
grep("ab", dd)
grepl("ab", dd)
grepl("a", dd)
grepl("f", dd)
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_Cols <- grep("^IL",training)
colnames(IL_Cols)
IL_Cols <- grep("^IL",colnames(training))
colnames(IL_Cols)
colnames(training)
grep("IL",colnames(training))
grep("^IL",colnames(training))
IL_Vals <- training[,IL_Cols]
data <- rbind(training[,1],IL_Vals)
data <- cbind(training[,1],IL_Vals)
colnames(data)
cols <- colnames(data[,2:13])
cols <- cbind("diagnosis", cols)
cols
cols <- colnames(data[,2:13])
cols <- c("diagnosis",cols)
cols
colnames(data) <- cols
colnames(data)
fitN <- train(diagnosis ~ ., method="glm", data = data)
fitP <- train(diagnosis ~ ., method="glm", preProcess="pca", thresh=.80, data = data)
fitP <- train(diagnosis ~ ., method="glm", preProcess="pca", data = data)
fitP <- train(diagnosis ~ ., method="glm", preProcess="pca",thresh=0.8, data = data)
?preProcess
rm(fitP)
data(,1)
data[,1]
test[,1]
testing[,1]
testing[,1] = data[,1]
which(testing[,1] == data[,1])
testing[,1] == data[,1]
predict(fitN, testing)
predN <- predict(fitN, testing)
predN == testing[,1]
sum(predN == testing[,1])
53/82*100
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
rm(list=ls())
library(caret)
data(segmentationData)
summary(segmentationData)
?subset
nrows(subset(segmentationData, Case== "Train"))
nrow(subset(segmentationData, Case== "Train"))
segmentationData$Cell <- NULL
training <- subset(segmentationData, Case == "Train")
testing <- subset(segmentationData, Case == "Test")
training$Case <- NULL
testing$Case <- NULL
trainX <- training[, names(training) != "Class"]
preProcValues <- preProcess(trainX, method = c("center", "scale"))
preProcValues
scaledTrain <- predict(preProcValues, trainX)
summary(scaledTrain[,1:6])
summary(trainX[,1:6])
setwd("~/DScience/Machine/Data")
rm(dd)
rm(diagnosis)
rm(intrain)
rm(inTrain)
rm(testing)
rm(adData)
rm(predictors)
rm(training)
require(caret)
set.seed(1234)
training <- read.csv("pml-training.csv")
training <- training[training$new_window=="no",]
training[,"new_window"] <- NULL
list <- as.vector(apply(training, 2, function(x){sum(is.na(x))}))
subset <- list==0
training<- training[,subset]
list <- as.vector(apply(training, 2, function(x){sum(x=="")}))
subset <- list==0
training<- training[,subset]
training[,"X"] <- NULL
training[,"raw_timestamp_part_1"] <- NULL
training[,"raw_timestamp_part_2"] <- NULL
training[,"cvtd_timestamp"] <- NULL
training[,"num_window"] <- NULL
inTrain <- createDataPartition(training$classe, p=.75, list=F)
train <- training[inTrain,]
validation <- training[-inTrain,]
predictors <- train[,-54]
?preproc
?preProc
?predict
?preProcess
preProc <- preProces(predictors,method"pca",thresh=0.8)
preProc <- preProcess(predictors,method"pca",thresh=0.8)
preProc <- preProcess(predictors,method="pca",thresh=0.8)
predictors <- predictors[,-1]
preProc <- preProcess(predictors,method="pca",thresh=0.8)
predictors <- validation[,-54]
predictors <- predictors[,-1]
modelFit <- train(classe ~ predictors, methord="rf",preProcess="pca",data=training)
modelFit <- train(classe ~ predictors, methord="rf",preProcess="pca",data=validation)
modelFit <- train(validationclasse ~ predictors, methord="rf",preProcess="pca",data=validation)
modelFit <- train(validation$classe ~ predictors, methord="rf",preProcess="pca",data=validation)
validation<- validation[,-1]
modelFit <- train(validation$classe ~ ., methord="rf",preProcess="pca",data=validation)
warnings()
test<- read.csv("pml-testing.csv")
confusionMatrix(test$classe, predict(modelFit, test))
predict(modelFit, test)
rm(list=ls())
set.seed(1234)
training <- read.csv("pml-training.csv")
training <- training[training$new_window=="no",]
training[,"new_window"] <- NULL
list <- as.vector(apply(training, 2, function(x){sum(is.na(x))}))
subset <- list==0
training<- training[,subset]
list <- as.vector(apply(training, 2, function(x){sum(x=="")}))
subset <- list==0
training<- training[,subset]
training[,"X"] <- NULL
training[,"raw_timestamp_part_1"] <- NULL
training[,"raw_timestamp_part_2"] <- NULL
training[,"cvtd_timestamp"] <- NULL
training[,"num_window"] <- NULL
?nearzerovar
?nearZeroVar
nearZeroVar(training)
list <- as.vector(apply(training, 2, function(x){nearZreoVar(x))}))
list <- as.vector(apply(training, 2, function(x){nearZreoVar(x)}))
list <- as.vector(apply(training, 2, function(x){nearZeroVar(x)}))
list <- apply(training, 2, function(x){nearZeroVar(x)})
apply(training, 2, function(x){nearZeroVar(x)})
nearZeroVar(training[,2:53])
nearZeroVar(training[,2:53],save metrics)
nearZeroVar(training[,2:53],saveMetrics=T)
inTrain <- createDataPartition(training$classe, p=.75, list=F)
train <- training[inTrain,]
validation <- training[-inTrain,]
install.packages(randomForest)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
?randomForest
